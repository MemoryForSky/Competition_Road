{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.txt', header=None, names=['pid', 'label', 'gender', 'age', 'tagid', 'time', 'province', 'city', 'make', 'model'])\n",
    "test = pd.read_csv('./data/apply_new.txt', header=None, names=['pid', 'gender', 'age', 'tagid', 'time', 'province', 'city', 'make', 'model'])\n",
    "data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tagid'] = data['tagid'].apply(lambda x: eval(x))\n",
    "sentences = data['tagid'].values.tolist()\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [str(x) for x in sentences[i]]\n",
    "\n",
    "emb_size = 32\n",
    "model = Word2Vec(sentences, vector_size=emb_size, window=6, min_count=5, sg=0, hs=0, seed=1, epochs=5)\n",
    "\n",
    "emb_matrix = []\n",
    "for seq in sentences:\n",
    "    vec = []\n",
    "    for w in seq:\n",
    "        if w in model.wv:\n",
    "            vec.append(model.wv.get_vector(w))\n",
    "    if len(vec) > 0:\n",
    "        emb_matrix.append(np.mean(vec, axis=0))\n",
    "    else:\n",
    "        emb_matrix.append([0] * emb_size)\n",
    "emb_matrix = np.array(emb_matrix)\n",
    "for i in range(emb_size):\n",
    "    data['tag_emb_{}'.format(i)] = emb_matrix[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "trn_idx: [     0      1      2 ... 299997 299998 299999]\n",
      "val_idx: [     3      9     14 ... 299992 299993 299994]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.290596\tvalid_1's binary_error: 0.312317\n",
      "[200]\ttraining's binary_error: 0.273738\tvalid_1's binary_error: 0.309217\n",
      "[300]\ttraining's binary_error: 0.263133\tvalid_1's binary_error: 0.308483\n",
      "Early stopping, best iteration is:\n",
      "[308]\ttraining's binary_error: 0.262408\tvalid_1's binary_error: 0.3076\n",
      "fold n°1\n",
      "trn_idx: [     0      1      2 ... 299996 299998 299999]\n",
      "val_idx: [    10     13     25 ... 299986 299988 299997]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.292612\tvalid_1's binary_error: 0.311617\n",
      "[200]\ttraining's binary_error: 0.2748\tvalid_1's binary_error: 0.308333\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's binary_error: 0.272587\tvalid_1's binary_error: 0.3074\n",
      "fold n°2\n",
      "trn_idx: [     0      3      5 ... 299997 299998 299999]\n",
      "val_idx: [     1      2      4 ... 299961 299977 299982]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.291729\tvalid_1's binary_error: 0.312383\n",
      "[200]\ttraining's binary_error: 0.273529\tvalid_1's binary_error: 0.308333\n",
      "[300]\ttraining's binary_error: 0.264\tvalid_1's binary_error: 0.307467\n",
      "[400]\ttraining's binary_error: 0.256537\tvalid_1's binary_error: 0.306517\n",
      "Early stopping, best iteration is:\n",
      "[388]\ttraining's binary_error: 0.257292\tvalid_1's binary_error: 0.306333\n",
      "fold n°3\n",
      "trn_idx: [     0      1      2 ... 299993 299994 299997]\n",
      "val_idx: [     5      6     12 ... 299996 299998 299999]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.2918\tvalid_1's binary_error: 0.31275\n",
      "[200]\ttraining's binary_error: 0.2748\tvalid_1's binary_error: 0.308667\n",
      "Early stopping, best iteration is:\n",
      "[215]\ttraining's binary_error: 0.272904\tvalid_1's binary_error: 0.307983\n",
      "fold n°4\n",
      "trn_idx: [     1      2      3 ... 299997 299998 299999]\n",
      "val_idx: [     0      7      8 ... 299967 299972 299973]\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.29215\tvalid_1's binary_error: 0.311783\n",
      "[200]\ttraining's binary_error: 0.274496\tvalid_1's binary_error: 0.308983\n",
      "[300]\ttraining's binary_error: 0.264112\tvalid_1's binary_error: 0.308117\n",
      "Early stopping, best iteration is:\n",
      "[257]\ttraining's binary_error: 0.26825\tvalid_1's binary_error: 0.307467\n",
      "AUC score: 0.7619250359111112\n",
      "F1 score: 0.686674482219617\n",
      "Precision score: 0.7002737637315036\n",
      "Recall score: 0.6735933333333334\n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['gender', 'age', 'province', 'city']\n",
    "features = [i for i in data.columns if i not in ['pid', 'label', 'tagid', 'time', 'model', 'make']]\n",
    "\n",
    "data[cat_cols] = data[cat_cols].astype('category')\n",
    "X_train = data[~data['label'].isna()]\n",
    "X_test = data[data['label'].isna()]\n",
    "\n",
    "y = X_train['label']\n",
    "KF = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "params = {\n",
    "          'objective':'binary',\n",
    "          'metric':'binary_error',\n",
    "          'learning_rate':0.05,\n",
    "          'subsample':0.8,\n",
    "          'subsample_freq':3,\n",
    "          'colsample_btree':0.8,\n",
    "          'num_iterations': 10000,\n",
    "          'verbose':-1\n",
    "}\n",
    "oof_lgb = np.zeros(len(X_train))\n",
    "predictions_lgb = np.zeros((len(X_test)))\n",
    "# 特征重要性\n",
    "feat_imp_df = pd.DataFrame({'feat': features, 'imp': 0})\n",
    "# 五折交叉验证\n",
    "for fold_, (trn_idx, val_idx) in enumerate(KF.split(X_train.values, y.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    print('trn_idx:',trn_idx)\n",
    "    print('val_idx:',val_idx)\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx][features],label=y.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx][features],label=y.iloc[val_idx])\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(\n",
    "        params,\n",
    "        trn_data,\n",
    "        num_round,\n",
    "        valid_sets = [trn_data, val_data],\n",
    "        verbose_eval=100,\n",
    "        early_stopping_rounds=50,\n",
    "        categorical_feature=cat_cols,\n",
    "    )\n",
    "    feat_imp_df['imp'] += clf.feature_importance() / 5\n",
    "    oof_lgb[val_idx] = clf.predict(X_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    predictions_lgb[:] += clf.predict(X_test[features], num_iteration=clf.best_iteration)\n",
    "print(\"AUC score: {}\".format(roc_auc_score(y, oof_lgb)))\n",
    "print(\"F1 score: {}\".format(f1_score(y, [1 if i >= 0.5 else 0 for i in oof_lgb])))\n",
    "print(\"Precision score: {}\".format(precision_score(y, [1 if i >= 0.5 else 0 for i in oof_lgb])))\n",
    "print(\"Recall score: {}\".format(recall_score(y, [1 if i >= 0.5 else 0 for i in oof_lgb])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['category_id'] = [1 if i >= 2.5 else 0 for i in predictions_lgb]\n",
    "X_test['user_id'] = X_test['pid']\n",
    "X_test[['user_id', 'category_id']].to_csv('base_wv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>city</td>\n",
       "      <td>4694.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>tag_emb_28</td>\n",
       "      <td>212.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>tag_emb_29</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tag_emb_7</td>\n",
       "      <td>167.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tag_emb_8</td>\n",
       "      <td>166.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tag_emb_6</td>\n",
       "      <td>161.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tag_emb_18</td>\n",
       "      <td>153.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tag_emb_25</td>\n",
       "      <td>151.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tag_emb_21</td>\n",
       "      <td>147.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>tag_emb_31</td>\n",
       "      <td>146.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tag_emb_22</td>\n",
       "      <td>140.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tag_emb_2</td>\n",
       "      <td>140.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tag_emb_16</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tag_emb_0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tag_emb_23</td>\n",
       "      <td>129.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>tag_emb_26</td>\n",
       "      <td>125.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tag_emb_3</td>\n",
       "      <td>119.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tag_emb_24</td>\n",
       "      <td>113.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age</td>\n",
       "      <td>105.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tag_emb_10</td>\n",
       "      <td>89.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tag_emb_27</td>\n",
       "      <td>87.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tag_emb_12</td>\n",
       "      <td>87.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tag_emb_30</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tag_emb_13</td>\n",
       "      <td>83.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tag_emb_9</td>\n",
       "      <td>80.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tag_emb_14</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tag_emb_11</td>\n",
       "      <td>60.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tag_emb_4</td>\n",
       "      <td>54.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tag_emb_15</td>\n",
       "      <td>49.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tag_emb_19</td>\n",
       "      <td>46.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tag_emb_17</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tag_emb_20</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tag_emb_5</td>\n",
       "      <td>33.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tag_emb_1</td>\n",
       "      <td>29.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gender</td>\n",
       "      <td>27.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>province</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feat     imp\n",
       "3         city  4694.4\n",
       "32  tag_emb_28   212.8\n",
       "33  tag_emb_29   178.0\n",
       "11   tag_emb_7   167.6\n",
       "12   tag_emb_8   166.4\n",
       "10   tag_emb_6   161.4\n",
       "22  tag_emb_18   153.2\n",
       "29  tag_emb_25   151.2\n",
       "25  tag_emb_21   147.4\n",
       "35  tag_emb_31   146.8\n",
       "26  tag_emb_22   140.8\n",
       "6    tag_emb_2   140.2\n",
       "20  tag_emb_16   137.0\n",
       "4    tag_emb_0   136.0\n",
       "27  tag_emb_23   129.8\n",
       "30  tag_emb_26   125.4\n",
       "7    tag_emb_3   119.8\n",
       "28  tag_emb_24   113.2\n",
       "1          age   105.6\n",
       "14  tag_emb_10    89.2\n",
       "31  tag_emb_27    87.4\n",
       "16  tag_emb_12    87.2\n",
       "34  tag_emb_30    86.0\n",
       "17  tag_emb_13    83.2\n",
       "13   tag_emb_9    80.8\n",
       "18  tag_emb_14    63.2\n",
       "15  tag_emb_11    60.8\n",
       "8    tag_emb_4    54.6\n",
       "19  tag_emb_15    49.8\n",
       "23  tag_emb_19    46.4\n",
       "21  tag_emb_17    45.0\n",
       "24  tag_emb_20    43.0\n",
       "9    tag_emb_5    33.2\n",
       "5    tag_emb_1    29.2\n",
       "0       gender    27.2\n",
       "2     province    16.8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_df.sort_values(by='imp', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
